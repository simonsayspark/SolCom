import streamlit as st
import pandas as pd
from datetime import datetime
from bd.column_mapping import apply_column_remap

def analyze_and_process_excel(uploaded_file, file_type="Auto-detectar"):
    """Advanced Excel analysis and processing based on actual user table structure"""
    try:
        # Read the Excel file to understand structure
        xl_file = pd.ExcelFile(uploaded_file)
        sheets = xl_file.sheet_names
        
        st.info(f"ğŸ“‹ Planilhas encontradas: {sheets}")
        
        # Try different sheets and header positions
        best_sheet = None
        best_header_row = 0
        best_df = None
        best_score = 0
        
        # Try different starting rows to find headers - expanded range
        for sheet in sheets[:5]:  # Check first 5 sheets
            for header_row in [0, 8, 9, 10, 7, 6, 11, 12]:
                try:
                    df_sample = pd.read_excel(uploaded_file, sheet_name=sheet, header=header_row, nrows=20)
                    
                    # Check if we found real headers (not None or Unnamed)
                    valid_columns = 0
                    real_headers = []
                    
                    for col in df_sample.columns:
                        col_str = str(col).strip()
                        if (col_str != 'None' and 
                            not col_str.startswith('Unnamed') and 
                            col_str != 'nan' and
                            len(col_str) > 0):
                            valid_columns += 1
                            real_headers.append(col_str)
                    
                    # Score this attempt
                    data_rows = len(df_sample.dropna(how='all'))
                    score = valid_columns * data_rows
                    
                    if score > best_score and valid_columns >= 3 and data_rows >= 3:
                        best_score = score
                        best_sheet = sheet
                        best_header_row = header_row
                        best_df = df_sample
                        
                except Exception as e:
                    continue
        
        if best_df is not None:
            # Load the full dataset
            df_full = pd.read_excel(uploaded_file, sheet_name=best_sheet, header=best_header_row)
            df_full = df_full.dropna(how='all')  # Remove completely empty rows
            
            # ğŸ”§ CRITICAL FIX: Apply column renaming BEFORE upload to fix zero prices issue
            st.info("ğŸ”„ Padronizando nomes das colunas...")
            
            original_columns = list(df_full.columns)
            df_full, change_pairs = apply_column_remap(df_full)
            renamed_columns = list(df_full.columns)

            changes_made = [f"'{old}' â†’ '{new}'" for old, new in change_pairs]
            
            if changes_made:
                st.success(f"âœ… Colunas padronizadas: {len(changes_made)} alteraÃ§Ãµes")
                with st.expander("ğŸ“‹ Ver alteraÃ§Ãµes nas colunas"):
                    for change in changes_made:
                        st.write(f"â€¢ {change}")
                        
                # Show critical price column fix
                if any('Preco_Unitario' in change for change in changes_made):
                    st.success("ğŸ”§ **CORREÃ‡ÃƒO CRÃTICA**: Coluna de preÃ§os padronizada - isso deve resolver o problema de preÃ§os zero!")
                
                # ğŸ”§ DEBUG: Check if PrevisÃ£o Total column was processed
                # Commented out to reduce debug spam
                # previsao_changes = [change for change in changes_made if 'Previsao_Total_New_Pos' in change or 'Previsao' in change]
                # if previsao_changes:
                #     st.success("ğŸ”§ **PREVISÃƒO TOTAL ENCONTRADA**: " + previsao_changes[0])
                # else:
                #     st.warning("âš ï¸ **PREVISÃƒO TOTAL NÃƒO ENCONTRADA** - Verifique se a coluna existe no Excel")
                #     
                #     # Show available columns that might be PrevisÃ£o Total
                #     previsao_candidates = [col for col in original_columns if 'previs' in col.lower() or 'total' in col.lower()]
                #     if previsao_candidates:
                #         st.info(f"ğŸ” Colunas candidatas encontradas: {', '.join(previsao_candidates)}")
                #     
                #     # Show exact column names for debugging
                #     st.info(f"ğŸ“‹ Todas as colunas originais: {', '.join(original_columns[:10])}{'...' if len(original_columns) > 10 else ''}")
            
            # ğŸ”§ NEW: Detect if this is a merged Excel file with priority analysis
            priority_columns = ['priority_score', 'criticality', 'relevance_class', 'preco_unitario']
            has_priority_data = any(col in df_full.columns for col in priority_columns)
            
            if has_priority_data:
                st.success("ğŸ¯ **MERGED EXCEL DETECTADO**: Este arquivo contÃ©m dados de anÃ¡lise prioritÃ¡ria!")
                detected_priority_cols = [col for col in priority_columns if col in df_full.columns]
                st.info(f"ğŸ“Š Colunas de prioridade encontradas: {', '.join(detected_priority_cols)}")
            else:
                st.info("ğŸ“Š **EXCEL PADRÃƒO**: Dados bÃ¡sicos de estoque detectados")
            
            st.success(f"âœ… Detectado automaticamente: planilha '{best_sheet}', linha {best_header_row + 1}")
            return df_full, best_sheet, best_header_row
        else:
            st.warning("âš ï¸ DetecÃ§Ã£o automÃ¡tica falhou. Usando primeira planilha, linha 1.")
            df_full = pd.read_excel(uploaded_file, sheet_name=sheets[0], header=0)
            return df_full, sheets[0], 0
                        
    except Exception as e:
        st.error(f"âŒ Erro ao analisar Excel: {str(e)}")
        return None, None, 0

def show_data_upload():
    """Upload functionality for multi-company data"""
    st.header("ğŸ“ Central de Upload de Dados Multi-Empresa")
    st.markdown("**Upload seus arquivos Excel aqui. Os dados serÃ£o salvos na nuvem com controle de versÃ£o para cada empresa.**")
    
    # Import Snowflake functions
    try:
        from bd.snowflake_config import (upload_excel_to_snowflake, load_data_with_history, 
                                        load_analytics_data, test_connection, get_upload_versions, 
                                        delete_version, fix_active_versions)
        from bd.snowflake_upload_dashboard import get_cached_upload_page_data
        from bd.snowflake_upload_optimized import upload_excel_to_snowflake_optimized
        snowflake_available = True
    except ImportError:
        snowflake_available = False
    
    # Company selection
    st.subheader("ğŸ¢ SeleÃ§Ã£o da Empresa")
    col1, col2 = st.columns(2)
    
    with col1:
        empresa_selecionada = st.radio(
            "Selecione a empresa:",
            ["ğŸ¢ MINIPA", "ğŸ­ MINIPA INDUSTRIA"],
            index=0
        )
        empresa_code = "MINIPA" if empresa_selecionada == "ğŸ¢ MINIPA" else "MINIPA_INDUSTRIA"
    
    with col2:
        st.info(f"""
        **Empresa Selecionada:** {empresa_selecionada}
        
        ğŸ“Š **Isolamento de Dados:**
        - Cada empresa tem seus prÃ³prios dados
        - Controle de versÃ£o independente  
        - HistÃ³rico completo por empresa
        """)
    
    # Show current data status
    if snowflake_available:
        st.subheader(f"ğŸ“Š Status dos Dados - {empresa_selecionada}")
        
        # Get ALL data in ONE Snowflake connection call
        dashboard_data = get_cached_upload_page_data(empresa_code)
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # Show timeline data
            timeline_stats = dashboard_data['stats']['timeline']
            timeline_count = timeline_stats.get('count', 0)
            
            if timeline_count > 0:
                st.success(f"ğŸ“… Timeline: {timeline_count} produtos salvos")
                if timeline_stats.get('latest_upload'):
                    st.info(f"ğŸ•’ Ãšltimo upload Timeline: {timeline_stats['latest_upload']}")
                st.info(f"ğŸ­ Fornecedores: {timeline_stats.get('suppliers', 0)}")
            else:
                st.info("ğŸ“… Timeline: Nenhum dado encontrado")
            
            # Show analytics data
            analytics_stats = dashboard_data['stats']['analytics']
            analytics_count = analytics_stats.get('count', 0)
            
            if analytics_count > 0:
                st.success(f"ğŸ“Š Analytics: {analytics_count} produtos salvos")
                if analytics_stats.get('latest_upload'):
                    st.info(f"ğŸ•’ Ãšltimo upload Analytics: {analytics_stats['latest_upload']}")
                st.info(f"ğŸ­ Fornecedores: {analytics_stats.get('suppliers', 0)}")
            else:
                st.info("ğŸ“Š Analytics: Nenhum dado encontrado")
            
            # Show version history with delete options
            with st.expander(f"ğŸ“‹ HistÃ³rico de VersÃµes - {empresa_selecionada}", expanded=True):
                try:
                    # Use the data we already fetched
                    versions_timeline = dashboard_data['versions_timeline']
                    versions_analytics = dashboard_data['versions_analytics']
                    
                    if versions_timeline:
                        st.write("**ğŸ“… Timeline de Compras:**")
                        for i, v in enumerate(versions_timeline[:5]):
                            status_icon = "ğŸŸ¢" if v['is_active'] else "âšª"
                            
                            # Use custom description or fallback to version number
                            display_name = v.get('description', '').strip()
                            if not display_name:
                                display_name = f"VersÃ£o {v['version_id']}"
                            
                            # Show filename if available
                            filename_info = f" - ğŸ“ {v.get('arquivo_origem', 'N/A')}" if v.get('arquivo_origem') else ""
                            
                            # Create a container for each version
                            version_container = st.container()
                            with version_container:
                                col1, col2 = st.columns([4, 1])
                                with col1:
                                    st.write(f"{status_icon} **{display_name}** - {v['upload_date']}{filename_info}")
                                with col2:
                                    if not v['is_active']:  # Can't delete active version
                                        delete_button = st.button("ğŸ—‘ï¸ Deletar", 
                                                                 key=f"del_timeline_{v['version_id']}_{i}", 
                                                                 help="Deletar esta versÃ£o",
                                                                 type="secondary",
                                                                 use_container_width=True)
                                        if delete_button:
                                            st.session_state[f"confirm_delete_timeline_{v['version_id']}"] = True
                                            st.rerun()
                                    else:
                                        st.write("ğŸ”’ **Ativa**")
                                
                                # Show confirmation dialog
                                if st.session_state.get(f"confirm_delete_timeline_{v['version_id']}", False):
                                    st.error(f"âš ï¸ **CONFIRMAR EXCLUSÃƒO:** {display_name}")
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        if st.button("âœ… SIM, DELETAR", 
                                                    key=f"confirm_del_timeline_{v['version_id']}",
                                                    type="primary",
                                                    use_container_width=True):
                                            # Use the consolidated function for deletion
                                            delete_data = get_cached_upload_page_data(
                                                empresa_code,
                                                delete_version_id=v['version_id'],
                                                delete_table_type="TIMELINE"
                                            )
                                            if delete_data['delete_result'] and delete_data['delete_result']['success']:
                                                st.success(f"âœ… {display_name} deletada!")
                                                get_cached_upload_page_data.clear()  # Clear cache
                                                st.session_state[f"confirm_delete_timeline_{v['version_id']}"] = False
                                                st.rerun()
                                            else:
                                                st.error("âŒ Falha ao deletar versÃ£o")
                                    with col2:
                                        if st.button("âŒ Cancelar", 
                                                    key=f"cancel_del_timeline_{v['version_id']}",
                                                    use_container_width=True):
                                            st.session_state[f"confirm_delete_timeline_{v['version_id']}"] = False
                                            st.rerun()
                                
                                st.divider()  # Visual separator between versions
                    
                    if versions_analytics:
                        st.write("**ğŸ“Š AnÃ¡lise de Estoque:**")
                        for i, v in enumerate(versions_analytics[:5]):
                            status_icon = "ğŸŸ¢" if v['is_active'] else "âšª"
                            
                            # Use custom description or fallback to version number
                            display_name = v.get('description', '').strip()
                            if not display_name:
                                display_name = f"VersÃ£o {v['version_id']}"
                            
                            # Show filename if available
                            filename_info = f" - ğŸ“ {v.get('arquivo_origem', 'N/A')}" if v.get('arquivo_origem') else ""
                            
                            # Create a container for each version
                            version_container = st.container()
                            with version_container:
                                col1, col2 = st.columns([4, 1])
                                with col1:
                                    st.write(f"{status_icon} **{display_name}** - {v['upload_date']}{filename_info}")
                                with col2:
                                    if not v['is_active']:  # Can't delete active version
                                        delete_button = st.button("ğŸ—‘ï¸ Deletar", 
                                                                 key=f"del_analytics_{v['version_id']}_{i}", 
                                                                 help="Deletar esta versÃ£o",
                                                                 type="secondary",
                                                                 use_container_width=True)
                                        if delete_button:
                                            st.session_state[f"confirm_delete_analytics_{v['version_id']}"] = True
                                            st.rerun()
                                    else:
                                        st.write("ğŸ”’ **Ativa**")
                                
                                # Show confirmation dialog
                                if st.session_state.get(f"confirm_delete_analytics_{v['version_id']}", False):
                                    st.error(f"âš ï¸ **CONFIRMAR EXCLUSÃƒO:** {display_name}")
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        if st.button("âœ… SIM, DELETAR", 
                                                    key=f"confirm_del_analytics_{v['version_id']}",
                                                    type="primary",
                                                    use_container_width=True):
                                            # Use the consolidated function for deletion
                                            delete_data = get_cached_upload_page_data(
                                                empresa_code,
                                                delete_version_id=v['version_id'],
                                                delete_table_type="ANALYTICS"
                                            )
                                            if delete_data['delete_result'] and delete_data['delete_result']['success']:
                                                st.success(f"âœ… {display_name} deletada!")
                                                get_cached_upload_page_data.clear()  # Clear cache
                                                st.session_state[f"confirm_delete_analytics_{v['version_id']}"] = False
                                                st.rerun()
                                            else:
                                                st.error("âŒ Falha ao deletar versÃ£o")
                                    with col2:
                                        if st.button("âŒ Cancelar", 
                                                    key=f"cancel_del_analytics_{v['version_id']}",
                                                    use_container_width=True):
                                            st.session_state[f"confirm_delete_analytics_{v['version_id']}"] = False
                                            st.rerun()
                                
                                st.divider()  # Visual separator between versions
                    
                    if not versions_timeline and not versions_analytics:
                        st.info("Nenhuma versÃ£o encontrada. FaÃ§a seu primeiro upload!")
                except Exception as e:
                    st.warning(f"Erro ao carregar versÃµes: {str(e)}")
        
        with col2:
            st.info("ğŸ”— Snowflake (monitoring disabled)")
            
            # Add database migration button
            if st.button("ğŸ”„ MigraÃ§Ã£o do BD", 
                        use_container_width=True,
                        help="Atualiza o banco de dados para suportar Excel merged com anÃ¡lise de prioridade"):
                try:
                    from bd.snowflake_migration import migrate_to_merged_excel_support
                    with st.spinner("ğŸ”„ Executando migraÃ§Ã£o do banco de dados..."):
                        if migrate_to_merged_excel_support():
                            st.success("âœ… MigraÃ§Ã£o concluÃ­da! O banco agora suporta dados merged Excel.")
                            st.info("ğŸ’¡ Agora vocÃª pode fazer upload de arquivos Excel merged com anÃ¡lise de prioridade.")
                        else:
                            st.error("âŒ Erro na migraÃ§Ã£o do banco de dados")
                except ImportError:
                    st.error("âŒ MÃ³dulo de migraÃ§Ã£o nÃ£o disponÃ­vel")
                except Exception as e:
                    st.error(f"âŒ Erro na migraÃ§Ã£o: {str(e)}")
            
            # Add repair button for version issues
            if st.button("ğŸ”§ Reparar VersÃµes", 
                        use_container_width=True,
                        help="Corrige o status 'ativa' das versÃµes - use se todas as versÃµes aparecem como ativas"):
                with st.spinner("ğŸ”§ Reparando status das versÃµes..."):
                    # Use the consolidated function for repair
                    repair_data = get_cached_upload_page_data(
                        empresa_code,
                        repair_versions=True
                    )
                    if repair_data['repair_result'] and repair_data['repair_result']['success']:
                        st.success(f"âœ… VersÃµes reparadas! {repair_data['repair_result']['fixed_count']} combinaÃ§Ãµes corrigidas.")
                        # Clear the cache to show updated data
                        get_cached_upload_page_data.clear()
                        get_upload_versions.clear()
                        st.rerun()
                    else:
                        st.error("âŒ Erro ao reparar versÃµes")
    
    # File upload section
    st.subheader(f"ğŸ“¤ Upload de Arquivo - {empresa_selecionada}")
    
    # Create two distinct upload options
    upload_type = st.radio(
        "ğŸ“‹ Selecione o tipo de dados:",
        ["ğŸ“Š AnÃ¡lise de Estoque com Prioridades (Merged Excel)", "ğŸ“… Timeline de Compras (MOQ/Fornecedores)", "ğŸ“Š AnÃ¡lise de Estoque (Export)"],
        help="Escolha o tipo correto para que os dados sejam processados adequadamente"
    )
    
    # Version description
    st.subheader("ğŸ“ DescriÃ§Ã£o da VersÃ£o")
    version_description = st.text_input(
        "DescriÃ§Ã£o desta versÃ£o (opcional):",
        placeholder="Ex: AtualizaÃ§Ã£o de preÃ§os Q4 2024, Novos fornecedores, etc.",
        help="Adicione uma descriÃ§Ã£o para identificar facilmente esta versÃ£o"
    )
    
    if upload_type == "ğŸ“Š AnÃ¡lise de Estoque com Prioridades (Merged Excel)":
        st.info("""
        ğŸ¯ **Para AnÃ¡lise com Prioridades:** Upload de Excel que jÃ¡ passou pelo processo de merge e priority analysis
        - Colunas esperadas: Produto, Estoque, MÃ©dia 6 Meses, preco_unitario, priority_score, criticality, etc.
        - Este formato Ã© gerado pelos scripts do Test folder (data_merger.py + priority_analysis.py)
        """)
        table_prefix = "ANALYTICS"
        uploaded_file = st.file_uploader(
            "ğŸ“ Arquivo Excel Merged com Prioridades",
            type=['xlsx', 'xls'],
            help="Arquivo que jÃ¡ passou pelo data merger e priority analysis",
            key="merged_upload"
        )
    elif upload_type == "ğŸ“… Timeline de Compras (MOQ/Fornecedores)":
        st.info("ğŸ“ **Para Timeline:** Upload com colunas Item, Fornecedor, QTD, Modelo, PreÃ§o FOB, MOQ, etc.")
        table_prefix = "TIMELINE"
        uploaded_file = st.file_uploader(
            "ğŸ“ Arquivo Excel para Timeline de Compras",
            type=['xlsx', 'xls'],
            help="Arquivo com dados de fornecedores, MOQ, preÃ§os FOB, etc.",
            key="timeline_upload"
        )
    else:
        st.info("ğŸ“Š **Para AnÃ¡lise:** Upload com colunas Produto, Estoque, MÃ©dia 6 Meses, Estoque Cobertura, etc.")
        table_prefix = "ANALYTICS"
        uploaded_file = st.file_uploader(
            "ğŸ“ Arquivo Excel para AnÃ¡lise de Estoque",
            type=['xlsx', 'xls'],
            help="Arquivo Export com dados de estoque e consumo",
            key="analytics_upload"
        )
    
    if uploaded_file is not None:
        st.subheader("ğŸ” AnÃ¡lise do Arquivo")
        
        if snowflake_available:
            try:
                # Use sophisticated Excel analysis to handle different header positions
                df_full, detected_sheet, detected_header = analyze_and_process_excel(uploaded_file)
                
                if df_full is not None and len(df_full) > 0:
                    st.success(f"âœ… Dados carregados: {len(df_full)} linhas")
                    st.dataframe(df_full.head(10))
                    
                    # Show data quality info
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("ğŸ“Š Linhas", len(df_full))
                    with col2:
                        st.metric("ğŸ“‹ Colunas", len(df_full.columns))
                    with col3:
                        st.metric("âœ… Valores vÃ¡lidos", df_full.count().sum())
                    with col4:
                        file_size = len(uploaded_file.getvalue()) / 1024
                        st.metric("ğŸ“ Tamanho", f"{file_size:.1f} KB")
                    
                    # Check for duplicate files - Get fresh data with duplicate check
                    file_hash = str(hash(str(df_full.values.tobytes())))
                    is_duplicate = False
                    
                    # Get fresh data that includes duplicate check for this specific file
                    upload_check_data = get_cached_upload_page_data(
                        empresa_code, 
                        table_prefix=table_prefix, 
                        uploaded_filename=uploaded_file.name
                    )
                    
                    if upload_check_data['duplicate_check'] and upload_check_data['duplicate_check']['is_duplicate']:
                        version = upload_check_data['duplicate_check']['version_info']
                        is_duplicate = True
                        st.warning(f"âš ï¸ **Arquivo duplicado detectado!** \n\nğŸ“ **{uploaded_file.name}** jÃ¡ foi enviado anteriormente como versÃ£o v{version['version_id']} em {version['upload_date']}")
                        
                        # Show option to proceed anyway
                        if st.checkbox("ğŸ”„ Enviar mesmo assim (criar nova versÃ£o)", key="force_upload"):
                            is_duplicate = False
                    
                    # Upload button
                    col1, col2 = st.columns([2, 1])
                    with col1:
                        upload_button = st.button("ğŸ’¾ Salvar na Nuvem", 
                                                 type="primary" if not is_duplicate else "secondary", 
                                                 use_container_width=True,
                                                 disabled=is_duplicate)
                    with col2:
                        if is_duplicate:
                            st.error("ğŸš« Duplicado")
                        else:
                            st.info(f"ğŸ“Š Para: {empresa_selecionada}")
                    
                    if upload_button:
                        with st.spinner(f"ğŸ“¤ Processando e enviando dados para Snowflake ({empresa_selecionada})..."):
                            try:
                                # Clean DataFrame for upload
                                df_clean = df_full.copy()
                                for col in df_clean.columns:
                                    if df_clean[col].dtype == 'object':
                                        df_clean[col] = df_clean[col].fillna('')
                                    else:
                                        df_clean[col] = df_clean[col].fillna(0)
                                
                                # Debug: Show consumption columns being uploaded
                                # Commented out to reduce debug spam
                                # if table_prefix == "ANALYTICS":
                                #     st.info("ğŸ” **Debug: Verificando colunas de consumo antes do upload:**")
                                #     consumo_cols = []
                                #     for col in ['Consumo 6 Meses', 'Consumo_6_Meses', 'MÃ©dia 6 Meses', 'Media_6_Meses']:
                                #         if col in df_clean.columns:
                                #             non_zero = len(df_clean[df_clean[col] > 0])
                                #             consumo_cols.append(f"â€¢ {col}: {non_zero} valores > 0")
                                #     
                                #     if consumo_cols:
                                #         st.success("âœ… Colunas de consumo encontradas:")
                                #         for info in consumo_cols:
                                #             st.write(info)
                                #     else:
                                #         st.warning("âš ï¸ Nenhuma coluna de consumo encontrada! Verifique os dados.")
                                
                                # Upload to Snowflake - Use optimized version
                                success = upload_excel_to_snowflake_optimized(
                                    df=df_clean, 
                                    arquivo_nome=uploaded_file.name, 
                                    empresa=empresa_code,
                                    usuario="minipa", 
                                    table_type=table_prefix,
                                    description=version_description or f"Upload {table_prefix} - {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}"
                                )
                                
                                if success:
                                    st.success(f"ğŸ‰ Dados salvos com sucesso para {empresa_selecionada}!")
                                    st.balloons()
                                    
                                    # Show different messages based on upload type
                                    if table_prefix == "TIMELINE":
                                        st.info("âœ… **Dados salvos para Timeline de Compras**")
                                        st.write("ğŸ‘‰ Acesse a pÃ¡gina 'ğŸ“… Timeline de Compras' para ver a anÃ¡lise")
                                    else:
                                        st.info("âœ… **Dados salvos para AnÃ¡lise de Estoque**") 
                                        st.write("ğŸ‘‰ Acesse a pÃ¡gina 'ğŸ“Š AnÃ¡lise de Estoque' para ver os relatÃ³rios")
                                    
                                    # Clear cache for this company to show new data immediately
                                    if table_prefix == "TIMELINE":
                                        load_data_with_history.clear()
                                    else:
                                        load_analytics_data.clear()
                                    
                                    # Clear version cache to show new version
                                    get_upload_versions.clear()
                                    
                                    # Also clear the new dashboard cache
                                    get_cached_upload_page_data.clear()
                                    
                                    st.rerun()
                                else:
                                    st.error(f"âŒ Erro ao salvar dados para {empresa_selecionada}")
                                    
                            except Exception as e:
                                st.error(f"âŒ Erro ao processar: {str(e)}")
                else:
                    st.error("âŒ NÃ£o foi possÃ­vel processar o arquivo")
                    st.info("ğŸ’¡ Verifique se o arquivo Excel tem dados vÃ¡lidos")
                    
            except Exception as e:
                st.error(f"âŒ Erro ao analisar arquivo: {str(e)}")
                st.info("ğŸ’¡ Tente com um arquivo Excel vÃ¡lido")
        else:
            st.warning("âš ï¸ Snowflake nÃ£o configurado. Dados serÃ£o usados apenas localmente.")
    
    # Additional help section
    with st.expander("ğŸ’¡ Dicas para Upload"):
        st.markdown("""
        **Formato de arquivo suportado:**
        - âœ… Arquivos Excel (.xlsx, .xls)
        - âœ… Headers a partir da linha 9 ou 10
        - âœ… Colunas: Item, Fornecedor, QTD, Modelo, PreÃ§o FOB, Estoque Total, In Transit, Avg Sales, CBM, MOQ
        
        **Para melhores resultados:**
        - ğŸ“‹ Certifique-se que os dados nÃ£o tenham linhas vazias no topo
        - ğŸ“Š NÃºmeros devem estar formatados como nÃºmeros (nÃ£o texto)
        - ğŸ”¤ Nomes de produtos devem estar na coluna 'Modelo' ou 'Item'
        """)
    
    # Show cloud data status
    if snowflake_available:
        st.divider()
        st.subheader("â˜ï¸ Status da Nuvem")
        if st.button("ğŸ”„ Recarregar dados da nuvem", use_container_width=True):
            st.rerun() 